  
 Lab 6 - Mount ADLS on Azure Databricks
 ---------------------------------------
 Ref: https://learn.microsoft.com/en-us/azure/databricks/dbfs/mounts
  
 NOTE: This is continuation of 'Lab 4 - Access ADLS using Service Principal'
 
 -> Make sure you have completed steps 1 to 7 from Lab 9
 
 1. Login to the Azure portal and make sure you have the following resources
    (Create them if not alreday there)
	
	1.1 A resource group (name: cts-demo-rg)
	1.2 A storage account (name: ctsdemosa) within the above resource group
	1.3 An Azure Databricks workspace (cts-demo-standard-eastus-ws)
			Pricing tier: Standard
			Region: East US
			
 2. Open the storage account and upload sample data into a container
 
	2.1 Open the Storage account page from the Azure portal
	2.2 Click on 'Containers' menu and click on '+ Container' to add.
		name: demo
	2.3 Open the container and click on 'Upload' to add the following file.
		file: circuits.csv
		
 3. Disable 'soft delete' for blobs and containers
 
	3.1 Open the Storage account page from the Azure portal
	3.2 Click on 'Data protection' option under 'Data management'
	3.3 Uncheck the following:
		Uncheck: Enable soft delete for blobs
		Uncheck: Enable soft delete for containers
	3.4 Click on 'Save' to save the changes
  
 
 4. Open your Databricks workspace and create an 'All purpose' cluster.
 
		name: CTS Demo Cluster
		Single node 
		Access mode: Single user
		Databricks runtime version: 13.3 LTS
		Uncheck 'Use Photon Acceleration'
		Node type: Standard_F4
		Terminate after 20 minutes of inactivity
		
		** Your cost should be 0.5 DBU/hour
			
 5. Register Microsoft Entra ID Application / Service Principal 
    NOTE: Microsoft Entra ID is formerly known as Microsoft Active Directory
	
	5.1 Search for and open 'Microsoft Entra ID' and Click on 'App registrations' menu option.
	5.2 Click on '+ Create an application' and create an app as below:
		name: cts-adls-using-sp-app
	5.3 Click on 'Register' button
	    This creates a Service Principal for us. 
	5.4 Make a note of the following details from the app registration page.
	
			Application (client) ID: <Application (client) ID>
			Directory (tenant) ID: <Directory (tenant) ID>
			
 6. Generate a secret/password for the Application
 
	6.1 Click on 'Certificates & secrets' on your app registration page.
	6.2 Click on '+ New Secret' button. 
	6.3 Create a secret as follows:
		Description: CTS ADLS Using Service Pricipal
		** DO NOT NAVIGATE AWAY FROM THIS PAGE UNTIL YOU COPY REQUIRED INFO **
	6.4 Make a note of the secret value (value, not id)
	
		Client Secret Value: <VALUE>
		
 7. Assign Role 'Storage Blob Data Contributor' to the Data Lake.
 
	7.1 Open your storage account page from Azure portal
	7.2 Click on 'Access Control (IAM)' option
	7.3 Click on 'Add' -> 'Add role assignment'
	7.4 Search for and select 'Storage Blob Contributor'. Click 'Next'
	7.5 Click on '+ Select members'
	7.6 Search for your service principal and add it.
	7.7 Click on 'Review + assign' and 'Review + assign' again 
	     
	** This adds 'Storage Blob Contributor' role on 'storage account' to 'service principal'.  
  
 8. Import the following notebook and run it.
	 Make sure to change 'storage account' and other variables as appropriate.
	
	Notebook: ADLS-Mount-using-Service-Principal.dbc	


  
	