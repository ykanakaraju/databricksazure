	
  Azure Databricks (44 hours)
  ------------------------------

   Databricks Basics
   PySpark Essentials
	- Spark basics
	- Spark SQL basics
	- Spark Structured Streaming basic
   Azure Databricks 
    	- Azure Databricks Architecture
    	- Workspaces & Storage Accounts
    	- Access Patterns
   	- Mount ADLS-Gen2 containers on Databricks
   Databricks Lakehouse Platform 
	â€“ Delta Lake Basics
	- Delta Lake Features
   ELT with Spark SQL
   Incremental Data Processing 
	- Structured Streaming
	- AutoLoader
   Production pipelines	
	- Delta Live Tables
   Data Governance
	- Unity Catalog


  Materials
  ---------
   - PDF presentations
   - Code Modules (PySpark)
   - Databricks Notebooks (DBC files)
   - Class notes
   - Github: https://github.com/ykanakaraju/databricksazure


  Getting started with Spark on Databricks
  ----------------------------------------   
   ** Databricks Community Edition (free edition)
 		
	Signup: https://www.databricks.com/try-databricks
		Screen 1: Fill up the details with valid email address
		Screen 2: Click on "Get started with Community Edition" link (Not the 'Continue' button)

	Login: https://community.cloud.databricks.com/login.html

	Downloading a file from Databricks
	----------------------------------
		/FileStore/<FILEPATH>
		https://community.cloud.databricks.com/files/<FILEPATH>?o=1072576993312365

		Example:
		dbfs:/FileStore/output/wc/part-00000
		https://community.cloud.databricks.com/files/output/wc/part-00000?o=1072576993312365

		dbfs:/FileStore/output/wordcount1/part-00000
		https://community.cloud.databricks.com/files/output/wordcount1/part-00000?o=1072576993312365


 	Enabling DBFS File browser
	--------------------------
	<your account (top-right)> -> Settings -> Advanced -> Other -> DBFS File Browser (enable it)
								    -> & refresh the browser page
  

  Databricks Basics
  -----------------
	
	1. Compute - Spin up cluster resources		
		1. All purpose clusters - continuously running, persistent cluster
		2. Job clusters - spinned up to execute a job and then terminated	

	2. Catalog
		-> All data is stored in Catalog
		-> All local files are store in /FileStore directory
		-> Default hive warehouse directory : /user/hive/warehouse

	3. Workspace
		-> All the notebooks are managed in the workspace



	
	













